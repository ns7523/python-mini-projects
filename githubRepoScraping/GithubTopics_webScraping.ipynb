{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "GithubTopics-webScraping.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n2j1rDDAH-H"
      },
      "source": [
        "## Github Topics Web Scraping\n",
        "\n",
        "### Libraries used:\n",
        "*   Beautiful Soup\n",
        "*   requests\n",
        "*   Pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE5AIfpbEHLY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXcmOBH5ELuV"
      },
      "source": [
        "### Scraping Process\n",
        "\n",
        "\n",
        "*   Scraping https://github.com/topics, https://github.com/python and https://github.com/javaScript\n",
        "*   Using requests module to get the page details\n",
        "*   Finding related tags or classes and creating functions\n",
        "*   Use beautful Soup to fetch data with the help of classes.\n",
        "*   Finding topics details with url, name and description\n",
        "*   For each repo fetching title, handler, stars and url\n",
        "*   Creating data frames and saving all data into the csv files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HSNgr4EAH-p"
      },
      "source": [
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_W-NqE-AH_s"
      },
      "source": [
        "topics_url = 'https://github.com/topics'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiGva69UAH_w"
      },
      "source": [
        "response = requests.get(topics_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJSZ4-dRAH_z",
        "outputId": "67acdf68-c1d9-4c2b-f7c2-3077a6aae74b"
      },
      "source": [
        "response.status_code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8YM0CCAAH_-"
      },
      "source": [
        "page_content = response.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzgGAOw2AIAB"
      },
      "source": [
        "with open('webpage.html', 'w', encoding='utf-8') as f:\n",
        "    f.write(page_content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ24szbvAIAG",
        "outputId": "e33d091a-4475-4b5f-a0db-a430f9a3e06e"
      },
      "source": [
        "# by using ! we directly install library on this jupyter notebook\n",
        "!pip install beautifulsoup4 --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: beautifulsoup4 in c:\\users\\welcome1\\anaconda3\\lib\\site-packages (4.9.3)\n",
            "Requirement already satisfied, skipping upgrade: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\welcome1\\anaconda3\\lib\\site-packages (from beautifulsoup4) (1.9.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElG89DTvAIAO"
      },
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peaeqD7eAIAS"
      },
      "source": [
        "doc = BeautifulSoup(page_content, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7ROgR8PAIAV",
        "outputId": "a5313aaa-e6b8-4624-fe6d-7cbfa5db1ac2"
      },
      "source": [
        "selection_class = \"f3 lh-condensed mb-0 mt-1 Link--primary\"\n",
        "topic_title_tags = doc.find_all('p', {'class':selection_class})\n",
        "len(topic_title_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnagMUj1AIAg",
        "outputId": "7503e73a-1637-4469-a76f-270e1ed18e0c"
      },
      "source": [
        "topic_titles = []\n",
        "for tag in topic_title_tags:\n",
        "    topic_titles.append(tag.text)\n",
        "    \n",
        "print(topic_titles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android', 'Angular', 'Ansible', 'API', 'Arduino', 'ASP.NET', 'Atom', 'Awesome Lists', 'Amazon Web Services', 'Azure', 'Babel', 'Bash', 'Bitcoin', 'Bootstrap', 'Bot', 'C', 'Chrome', 'Chrome extension', 'Command line interface', 'Clojure', 'Code quality', 'Code review', 'Compiler', 'Continuous integration', 'COVID-19', 'C++']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ1ccshHAIAx",
        "outputId": "c5d53a3f-8b59-435b-c58a-62eada7e6901"
      },
      "source": [
        "desc_selector = \"f5 color-text-secondary mb-0 mt-1\"\n",
        "topics_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
        "len(topics_desc_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDG-6jk8AIBJ",
        "outputId": "df836ee9-1155-476e-8eeb-167d4056b0f1"
      },
      "source": [
        "topics_description = []\n",
        "\n",
        "for tag in topics_desc_tags:\n",
        "    topics_description.append(tag.text.strip())\n",
        "    \n",
        "print(topics_description[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3D modeling is the process of virtually developing the surface and structure of a 3D object.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPr0WHfOAIBk"
      },
      "source": [
        "topics_link_tags = doc.find_all('a',{\"class\":\"d-flex no-underline\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oess-tklAIBx",
        "outputId": "61ea9c36-7122-4626-cc5b-406b173ddf52"
      },
      "source": [
        "base_url = \"https://github.com\"\n",
        "topic_urls = []\n",
        "\n",
        "for tag in topics_link_tags:\n",
        "    topic_urls.append(base_url + tag['href'])\n",
        "\n",
        "topic_urls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://github.com/topics/3d',\n",
              " 'https://github.com/topics/ajax',\n",
              " 'https://github.com/topics/algorithm',\n",
              " 'https://github.com/topics/amphp',\n",
              " 'https://github.com/topics/android',\n",
              " 'https://github.com/topics/angular',\n",
              " 'https://github.com/topics/ansible',\n",
              " 'https://github.com/topics/api',\n",
              " 'https://github.com/topics/arduino',\n",
              " 'https://github.com/topics/aspnet',\n",
              " 'https://github.com/topics/atom',\n",
              " 'https://github.com/topics/awesome',\n",
              " 'https://github.com/topics/aws',\n",
              " 'https://github.com/topics/azure',\n",
              " 'https://github.com/topics/babel',\n",
              " 'https://github.com/topics/bash',\n",
              " 'https://github.com/topics/bitcoin',\n",
              " 'https://github.com/topics/bootstrap',\n",
              " 'https://github.com/topics/bot',\n",
              " 'https://github.com/topics/c',\n",
              " 'https://github.com/topics/chrome',\n",
              " 'https://github.com/topics/chrome-extension',\n",
              " 'https://github.com/topics/cli',\n",
              " 'https://github.com/topics/clojure',\n",
              " 'https://github.com/topics/code-quality',\n",
              " 'https://github.com/topics/code-review',\n",
              " 'https://github.com/topics/compiler',\n",
              " 'https://github.com/topics/continuous-integration',\n",
              " 'https://github.com/topics/covid-19',\n",
              " 'https://github.com/topics/cpp']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DLVpPXfAICC"
      },
      "source": [
        "## Creating CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9qkPDaCAICF"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RcIPn6tAICQ"
      },
      "source": [
        "topics_dict=    {\n",
        "        'Title': topic_titles,\n",
        "        'Description': topics_description,\n",
        "        'URLs':topic_urls\n",
        "    }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9-zg9ifAIDu"
      },
      "source": [
        "topic_df = pd.DataFrame(topics_dict)\n",
        "topic_df.to_csv(\"githubTopics.csv\", index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvi5R2DAIDz"
      },
      "source": [
        "## Fetching information from topic links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLMRQFdEAID3"
      },
      "source": [
        "topic_page_url = topic_urls[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OIgjAYbAID6",
        "outputId": "e3fc3960-7cf3-419a-9179-861e94a3aa28"
      },
      "source": [
        "topic_page_url"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://github.com/topics/3d'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bAGlOySAID-"
      },
      "source": [
        "response = requests.get(topic_page_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OtV-F4WAIEA",
        "outputId": "647ebfc4-97c4-48e6-c15d-270d82a5f3a1"
      },
      "source": [
        "response.status_code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM83zIBpAIEI",
        "outputId": "9ed90bca-c667-41a9-d6da-81c1792b714c"
      },
      "source": [
        "len(response.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "612038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Moe_-MAIFI"
      },
      "source": [
        "topic_doc = BeautifulSoup(response.text, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Whm_uxaAIFL"
      },
      "source": [
        "topic_content = response.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXwN-HY9AIFN"
      },
      "source": [
        "with open('topicswebpage.html', 'w', encoding='utf-8') as f:\n",
        "    f.write(topic_content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAQYfYq4AIFP"
      },
      "source": [
        "h1_selection_class=\"f3 color-text-secondary text-normal lh-condensed\"\n",
        "repo_tags= topic_doc.find_all('h1', {'class':\"f3 color-text-secondary text-normal lh-condensed\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j_dabknAIFS",
        "outputId": "a7954b30-c741-42b6-d2ff-a4cbcbf6db5a"
      },
      "source": [
        "len(repo_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzFOnjhhAIFZ"
      },
      "source": [
        "a_tags = repo_tags[0].find_all('a')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmrzqxDgAIFe",
        "outputId": "7d5062ad-201d-422a-c2aa-356bbd0c55cb"
      },
      "source": [
        "a_tags[0].text.strip()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mrdoob'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s5_w-sMAIFh",
        "outputId": "46a14ad1-6356-4081-a618-39d85938ce10"
      },
      "source": [
        "a_tags[1].text.strip()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'three.js'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W82_eKDZAIFk",
        "outputId": "cff1eb0e-9983-448b-dd4c-dd36cd1875a3"
      },
      "source": [
        "repo_url = base_url + a_tags[1]['href']\n",
        "repo_url"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://github.com/mrdoob/three.js'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufd41DPzAIFp"
      },
      "source": [
        "star_tags = topic_doc.find_all('a',{'class': 'social-count float-none'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QmAQn1wAIFt",
        "outputId": "0bf644ef-a3b7-407f-dbc0-4565122ece6d"
      },
      "source": [
        "len(star_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VSZMg_IAIFx",
        "outputId": "30224a6a-5b7f-4f6e-cfdc-f6bc38993fd0"
      },
      "source": [
        "star_tags[0].text.strip()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'71.2k'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qll6w-wxAIGT"
      },
      "source": [
        "def parse_star_count(stars_str):\n",
        "    stars_str = stars_str.strip()\n",
        "    if stars_str[-1] == 'k':\n",
        "        return int(float(stars_str[:-1])*1000)\n",
        "    return int(stars_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gd1-X21AIIV",
        "outputId": "42b018b0-98c2-409a-fc67-6c0d776012e2"
      },
      "source": [
        "parse_star_count(star_tags[0].text.strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBASoDqjAII6"
      },
      "source": [
        "def get_repo_info(h1_tag, star_tag):\n",
        "    a_tags = h1_tag.find_all('a')\n",
        "    username = a_tags[0].text.strip()\n",
        "    repo_name = a_tags[1].text.strip()\n",
        "    repo_url = base_url + a_tags[1]['href']\n",
        "    stars = parse_star_count(star_tag.text.strip())\n",
        "    return username, repo_name, repo_url, stars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oP_hvvtAII-",
        "outputId": "27ceddc2-0e1a-4bb1-9788-20017b669990"
      },
      "source": [
        "get_repo_info(repo_tags[0], star_tags[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('mrdoob', 'three.js', 'https://github.com/mrdoob/three.js', 71200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtODyTnYAIJJ"
      },
      "source": [
        "### Combined all above code togather and creating usable funtions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heHXJKkEAIJO"
      },
      "source": [
        "Write a single function to:\n",
        "1. Get the topics list form main topic page\n",
        "2. Get the list of the top repos from the individual topic page\n",
        "3. Create a CSV file for topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbWe7p-dAIJY"
      },
      "source": [
        "def get_topic_titles(doc):\n",
        "    selection_class = \"f3 lh-condensed mb-0 mt-1 Link--primary\"\n",
        "    topic_title_tags = doc.find_all('p', {'class':selection_class})\n",
        "    topic_titles = []\n",
        "    for tag in topic_title_tags:\n",
        "        topic_titles.append(tag.text)\n",
        "    return topic_titles\n",
        "\n",
        "\n",
        "\n",
        "def get_topic_descs(doc):\n",
        "    desc_selector = \"f5 color-text-secondary mb-0 mt-1\"\n",
        "    topics_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
        "    topics_description = []\n",
        "    for tag in topics_desc_tags:\n",
        "        topics_description.append(tag.text.strip())\n",
        "    return topics_description\n",
        "    \n",
        "\n",
        "def get_topic_urls(doc):\n",
        "    topics_link_tags = doc.find_all('a',{\"class\":\"d-flex no-underline\"})\n",
        "    base_url = \"https://github.com\"\n",
        "    topic_urls = []\n",
        "    for tag in topics_link_tags:\n",
        "        topic_urls.append(base_url + tag['href'])\n",
        "\n",
        "    return topic_urls\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "def scrape_topics_repos():\n",
        "    topics_url = 'https://github.com/topics'\n",
        "    response = requests.get(topics_url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f'Failed to load page {topics_url}')\n",
        "    doc = BeautifulSoup(response.text, 'html.parser')\n",
        "    topics_dict={\n",
        "        'Title': get_topic_titles(doc),\n",
        "        'Description': get_topic_descs(doc),\n",
        "        'URLs': get_topic_urls(doc)\n",
        "    }\n",
        "    return pd.DataFrame(topics_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDplp_brAIJf",
        "outputId": "e00fcbcc-39cb-4a20-d299-6d3b1db1dc5a"
      },
      "source": [
        "scrape_topics_repos().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>URLs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3D</td>\n",
              "      <td>3D modeling is the process of virtually develo...</td>\n",
              "      <td>https://github.com/topics/3d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ajax</td>\n",
              "      <td>Ajax is a technique for creating interactive w...</td>\n",
              "      <td>https://github.com/topics/ajax</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Algorithm</td>\n",
              "      <td>Algorithms are self-contained sequences that c...</td>\n",
              "      <td>https://github.com/topics/algorithm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Amp</td>\n",
              "      <td>Amp is a non-blocking concurrency framework fo...</td>\n",
              "      <td>https://github.com/topics/amphp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Android</td>\n",
              "      <td>Android is an operating system built by Google...</td>\n",
              "      <td>https://github.com/topics/android</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Title                                        Description  \\\n",
              "0         3D  3D modeling is the process of virtually develo...   \n",
              "1       Ajax  Ajax is a technique for creating interactive w...   \n",
              "2  Algorithm  Algorithms are self-contained sequences that c...   \n",
              "3        Amp  Amp is a non-blocking concurrency framework fo...   \n",
              "4    Android  Android is an operating system built by Google...   \n",
              "\n",
              "                                  URLs  \n",
              "0         https://github.com/topics/3d  \n",
              "1       https://github.com/topics/ajax  \n",
              "2  https://github.com/topics/algorithm  \n",
              "3      https://github.com/topics/amphp  \n",
              "4    https://github.com/topics/android  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYAjQKWHAIJl"
      },
      "source": [
        "def get_topic_page(topic_url):\n",
        "    response = requests.get(topic_url)\n",
        "    # confirming response\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f'Failed to load page {topic_url}')\n",
        "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
        "    return topic_doc    \n",
        "\n",
        "\n",
        "def get_repo_info(h1_tag, star_tag):\n",
        "    a_tags = h1_tag.find_all('a')\n",
        "    username = a_tags[0].text.strip()\n",
        "    repo_name = a_tags[1].text.strip()\n",
        "    repo_url = base_url + a_tags[1]['href']\n",
        "    stars = parse_star_count(star_tag.text.strip())\n",
        "    return username, repo_name, repo_url, stars\n",
        "\n",
        "\n",
        "def get_topic_repos(topic_doc):\n",
        "    # getting repo tags\n",
        "    repo_tags= topic_doc.find_all('h1', {'class':\"f3 color-text-secondary text-normal lh-condensed\"})\n",
        "    # getting star tags\n",
        "    star_tags = topic_doc.find_all('a',{'class': 'social-count float-none'})\n",
        "    \n",
        "    topic_repos_dict = {\n",
        "    'username': [],\n",
        "    'repo_name':[],\n",
        "    'stars': [],\n",
        "    'repo_url': []\n",
        "}\n",
        "    \n",
        "    for i in range(len(repo_tags)):\n",
        "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
        "        topic_repos_dict['username'].append(repo_info[0])\n",
        "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
        "        topic_repos_dict['stars'].append(repo_info[3])\n",
        "        topic_repos_dict['repo_url'].append(repo_info[2])\n",
        "        \n",
        "    return pd.DataFrame(topic_repos_dict)\n",
        "\n",
        "\n",
        "def scrape_topic(topic_url, topic_name):\n",
        "    fname = topic_name + '.csv'\n",
        "    import os\n",
        "    if os.path.exists(fname):\n",
        "        print(f\"The file {fname} already exists!\")\n",
        "        return \n",
        "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
        "    topic_df.to_csv(fname, index=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVpzCRJIAIKC"
      },
      "source": [
        "doc = get_topic_page('https://github.com/topics/3d')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkZFsH-SAIKM"
      },
      "source": [
        "def scrape_topics_repos_df():\n",
        "    topics_df = scrape_topics_repos()\n",
        "    for index, row in topics_df.iterrows():\n",
        "        print('Scraping top repos for \"{}\"'.format(row['Title']))\n",
        "        scrape_topic(row['URLs'], 'data/{}'.format(row['Title']))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCbj3g3aAIKR",
        "outputId": "ec015f6e-aab2-49ff-c887-c97a950afbf3"
      },
      "source": [
        "scrape_topics_repos_df()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scraping top repos for \"3D\"\n",
            "The file data/3D.csv already exists!\n",
            "Scraping top repos for \"Ajax\"\n",
            "The file data/Ajax.csv already exists!\n",
            "Scraping top repos for \"Algorithm\"\n",
            "The file data/Algorithm.csv already exists!\n",
            "Scraping top repos for \"Amp\"\n",
            "The file data/Amp.csv already exists!\n",
            "Scraping top repos for \"Android\"\n",
            "The file data/Android.csv already exists!\n",
            "Scraping top repos for \"Angular\"\n",
            "The file data/Angular.csv already exists!\n",
            "Scraping top repos for \"Ansible\"\n",
            "The file data/Ansible.csv already exists!\n",
            "Scraping top repos for \"API\"\n",
            "The file data/API.csv already exists!\n",
            "Scraping top repos for \"Arduino\"\n",
            "The file data/Arduino.csv already exists!\n",
            "Scraping top repos for \"ASP.NET\"\n",
            "The file data/ASP.NET.csv already exists!\n",
            "Scraping top repos for \"Atom\"\n",
            "The file data/Atom.csv already exists!\n",
            "Scraping top repos for \"Awesome Lists\"\n",
            "The file data/Awesome Lists.csv already exists!\n",
            "Scraping top repos for \"Amazon Web Services\"\n",
            "The file data/Amazon Web Services.csv already exists!\n",
            "Scraping top repos for \"Azure\"\n",
            "The file data/Azure.csv already exists!\n",
            "Scraping top repos for \"Babel\"\n",
            "The file data/Babel.csv already exists!\n",
            "Scraping top repos for \"Bash\"\n",
            "The file data/Bash.csv already exists!\n",
            "Scraping top repos for \"Bitcoin\"\n",
            "The file data/Bitcoin.csv already exists!\n",
            "Scraping top repos for \"Bootstrap\"\n",
            "The file data/Bootstrap.csv already exists!\n",
            "Scraping top repos for \"Bot\"\n",
            "The file data/Bot.csv already exists!\n",
            "Scraping top repos for \"C\"\n",
            "The file data/C.csv already exists!\n",
            "Scraping top repos for \"Chrome\"\n",
            "The file data/Chrome.csv already exists!\n",
            "Scraping top repos for \"Chrome extension\"\n",
            "The file data/Chrome extension.csv already exists!\n",
            "Scraping top repos for \"Command line interface\"\n",
            "The file data/Command line interface.csv already exists!\n",
            "Scraping top repos for \"Clojure\"\n",
            "The file data/Clojure.csv already exists!\n",
            "Scraping top repos for \"Code quality\"\n",
            "The file data/Code quality.csv already exists!\n",
            "Scraping top repos for \"Code review\"\n",
            "The file data/Code review.csv already exists!\n",
            "Scraping top repos for \"Compiler\"\n",
            "The file data/Compiler.csv already exists!\n",
            "Scraping top repos for \"Continuous integration\"\n",
            "The file data/Continuous integration.csv already exists!\n",
            "Scraping top repos for \"COVID-19\"\n",
            "The file data/COVID-19.csv already exists!\n",
            "Scraping top repos for \"C++\"\n",
            "The file data/C++.csv already exists!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VUd3iMKAIKb"
      },
      "source": [
        "## Scraping Python repos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygWzRp9_AIKe"
      },
      "source": [
        "python_repo_url = \"https://github.com/topics/python\"\n",
        "python_topic_name = 'pythonRepos'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A9nJQd1AIKg"
      },
      "source": [
        "response = requests.get(python_repo_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE9FD2LJAIKi",
        "outputId": "30dd2bb8-d728-4e6e-f9f1-f1a94cadf650"
      },
      "source": [
        "response.status_code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auCLdjmFAIKw"
      },
      "source": [
        "python_page_content = response.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LM5OuESAIKy"
      },
      "source": [
        "python_doc = BeautifulSoup(python_page_content, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEt9K556AIK0"
      },
      "source": [
        "def get_python_page(python_repo_url):\n",
        "    response = requests.get(python_repo_url)\n",
        "    # confirming response\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f'Failed to load page {python_repo_url}')\n",
        "    python_doc = BeautifulSoup(response.text, 'html.parser')\n",
        "    return python_doc    \n",
        "\n",
        "\n",
        "def get_pythonrepo_info(h1_tag, star_tag):\n",
        "    a_tags = h1_tag.find_all('a')\n",
        "    username = a_tags[0].text.strip()\n",
        "    repo_name = a_tags[1].text.strip()\n",
        "    repo_url = base_url + a_tags[1]['href']\n",
        "    stars = parse_star_count(star_tag.text.strip())\n",
        "    return username, repo_name, repo_url, stars\n",
        "\n",
        "\n",
        "def get_python_repos(python_doc):\n",
        "    # getting repo tags\n",
        "    repo_tags= python_doc.find_all('h1', {'class':\"f3 color-text-secondary text-normal lh-condensed\"})\n",
        "    # getting star tags\n",
        "    star_tags = python_doc.find_all('a',{'class': 'social-count float-none'})\n",
        "    \n",
        "    topic_repos_dict = {\n",
        "    'username': [],\n",
        "    'repo_name':[],\n",
        "    'stars': [],\n",
        "    'repo_url': []\n",
        "}\n",
        "    \n",
        "    for i in range(len(repo_tags)):\n",
        "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
        "        topic_repos_dict['username'].append(repo_info[0])\n",
        "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
        "        topic_repos_dict['stars'].append(repo_info[3])\n",
        "        topic_repos_dict['repo_url'].append(repo_info[2])\n",
        "        \n",
        "    return pd.DataFrame(topic_repos_dict)\n",
        "\n",
        "\n",
        "def scrape_python_repo(python_repo_url, python_topic_name):\n",
        "    fname = python_topic_name + '.csv'\n",
        "    import os\n",
        "    if os.path.exists(fname):\n",
        "        print(f\"The file {fname} already exists!\")\n",
        "        return \n",
        "    python_df = get_python_repos(get_python_page(python_repo_url))\n",
        "    python_df.to_csv(fname, index=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_LZKORbAILP"
      },
      "source": [
        "scrape_python_repo(python_repo_url, python_topic_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeZU-crpAILT"
      },
      "source": [
        "### JavaScript repos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDAg-cFUAILV"
      },
      "source": [
        "javascript_repos_url = \"https://github.com/topics/javascript\"\n",
        "topic_name = \"javaScriptRepos\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGINtcIHAILf",
        "outputId": "da65c2e3-d333-41c0-d208-3a8551dec204"
      },
      "source": [
        "response = requests.get(javascript_repos_url)\n",
        "response.status_code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDU52W66AILk"
      },
      "source": [
        "javascript_page_content = response.text\n",
        "javascript_doc = BeautifulSoup(javascript_page_content, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98lqpUEaAILm"
      },
      "source": [
        "def get_javascript_page(javascript_repos_url):\n",
        "    response = requests.get(javascript_repos_url)\n",
        "    # confirming response\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f'Failed to load page {javascript_repos_urll}')\n",
        "    javascript_doc = BeautifulSoup(response.text, 'html.parser')\n",
        "    return javascript_doc    \n",
        "\n",
        "\n",
        "def get_javascriptrepo_info(h1_tag, star_tag):\n",
        "    a_tags = h1_tag.find_all('a')\n",
        "    username = a_tags[0].text.strip()\n",
        "    repo_name = a_tags[1].text.strip()\n",
        "    repo_url = base_url + a_tags[1]['href']\n",
        "    stars = parse_star_count(star_tag.text.strip())\n",
        "    return username, repo_name, repo_url, stars\n",
        "\n",
        "\n",
        "def get_javascript_repos(javascript_doc):\n",
        "    # getting repo tags\n",
        "    repo_tags= javascript_doc.find_all('h1', {'class':\"f3 color-text-secondary text-normal lh-condensed\"})\n",
        "    # getting star tags\n",
        "    star_tags = javascript_doc.find_all('a',{'class': 'social-count float-none'})\n",
        "    \n",
        "    topic_repos_dict = {\n",
        "    'username': [],\n",
        "    'repo_name':[],\n",
        "    'stars': [],\n",
        "    'repo_url': []\n",
        "}\n",
        "    \n",
        "    for i in range(len(repo_tags)):\n",
        "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
        "        topic_repos_dict['username'].append(repo_info[0])\n",
        "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
        "        topic_repos_dict['stars'].append(repo_info[3])\n",
        "        topic_repos_dict['repo_url'].append(repo_info[2])\n",
        "        \n",
        "    return pd.DataFrame(topic_repos_dict)\n",
        "\n",
        "\n",
        "def scrape_javascript_repo(javascript_repos_url, topic_name):\n",
        "    fname = topic_name + '.csv'\n",
        "    import os\n",
        "    if os.path.exists(fname):\n",
        "        print(f\"The file {fname} already exists!\")\n",
        "        return \n",
        "    javascript_df = get_javascript_repos(get_javascript_page(javascript_repos_url))\n",
        "    javascript_df.to_csv(fname, index=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAlNZjxZAILv"
      },
      "source": [
        "scrape_javascript_repo(javascript_repos_url, topic_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FBLlJo1AILy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE2xKH1_AIL0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}